{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch \n",
    "from collections import defaultdict\n",
    "import json \n",
    "import pathlib \n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = json.load(open(\"/brtx/603-nvme2/estengel/annotator_uncertainty/vqa/dev_from_mturk/annotations.json\"))['annotations']\n",
    "questions = json.load(open(\"/brtx/603-nvme2/estengel/annotator_uncertainty/vqa/dev_from_mturk/questions.json\"))['questions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the clusters from annotations \n",
    "def get_annotator_clusters(questions, annotations): \n",
    "    anns_by_qid = defaultdict(list)\n",
    "    for quest, ann in zip(questions, annotations):\n",
    "\n",
    "        qid, i = quest['question_id'].split(\"_\")\n",
    "        anns_by_qid[qid].append((quest, ann))\n",
    "\n",
    "    clusters_by_qid = {}\n",
    "    for qid, list_of_qas in anns_by_qid.items():\n",
    "        clusters = defaultdict(list)\n",
    "        for quest, ann in list_of_qas:\n",
    "            rewritten = quest['new_question']\n",
    "            answer = ann['answers'][0]['answer']\n",
    "            answer_id = ann['answers'][0]['mturk_id']\n",
    "            cluster_dict = {\"answer\": answer, \"id\": answer_id} \n",
    "            clusters[rewritten].append(cluster_dict)\n",
    "        clusters_by_qid[qid] = clusters\n",
    "    return clusters_by_qid\n",
    "\n",
    "# get the clusters from kmeans preprocessing\n",
    "def get_preprocessed_clusters(questions, annotations): \n",
    "    anns_by_qid = defaultdict(list)\n",
    "    for quest, ann in zip(questions, annotations):\n",
    "\n",
    "        qid, i = quest['question_id'].split(\"_\")\n",
    "        anns_by_qid[qid].append((quest, ann))\n",
    "\n",
    "    clusters_by_qid = {}\n",
    "    for qid, list_of_qas in anns_by_qid.items():\n",
    "        clusters = defaultdict(list)\n",
    "        for quest, ann in list_of_qas:\n",
    "            answer = ann['answers'][0]['answer']\n",
    "            answer_id = ann['answers'][0]['mturk_id']\n",
    "            id_key, answer_id_suffix = answer_id.split(\".\")\n",
    "            cluster_dict = {\"answer\": answer, \"id\": answer_id} \n",
    "            clusters[id_key].append(cluster_dict)\n",
    "        clusters_by_qid[qid] = clusters\n",
    "    return clusters_by_qid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "import scipy \n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "def read_generations(output_path):\n",
    "    flat_data_by_qid = {}\n",
    "    data = open(output_path).readlines()\n",
    "    for line in data:\n",
    "        batch_data = json.loads(line)\n",
    "        for qid, generation in zip(batch_data['question_id'], batch_data['speaker_utterances'][0]):\n",
    "            flat_data_by_qid[qid] = generation\n",
    "    return flat_data_by_qid\n",
    "\n",
    "def clean_text(text): \n",
    "    text = re.sub(\"<.*?>\", \"\", text)\n",
    "    text = text.strip() \n",
    "    return text \n",
    "\n",
    "# get the clusters from predictions \n",
    "def get_prediction_clusters(predictions_jsonl, questions, annotations, score_cls):\n",
    "    generations_by_qid = read_generations(predictions_jsonl)\n",
    "    anns_by_qid = defaultdict(list)\n",
    "    answers_by_qid = defaultdict(list)\n",
    "    for quest, ann in zip(questions, annotations):\n",
    "        qid, i = quest['question_id'].split(\"_\")\n",
    "        generation = clean_text(generations_by_qid[quest['question_id']])\n",
    "        anns_by_qid[qid].append(generation)\n",
    "        answers_by_qid[qid].append(ann['answers'])\n",
    "\n",
    "    scores_by_qid = {} \n",
    "    clusts_by_qid = {}\n",
    "    # Get matrix of scores \n",
    "    answer_clusters = {}\n",
    "    c = 0\n",
    "    for qid, quest_list in tqdm(anns_by_qid.items()): \n",
    "        scores = np.zeros((len(quest_list), len(quest_list))) \n",
    "        done = []\n",
    "        for i, q1 in enumerate(quest_list): \n",
    "            for j, q2 in enumerate(quest_list):\n",
    "                if i == j: \n",
    "                    scores[i,j] = 0.0 \n",
    "                    continue\n",
    "                sim_score = score_cls.get_similarity(q1, q2) \n",
    "                scores[i,j] = 1/sim_score\n",
    "                done.append((i,j))\n",
    "                done.append((j,i))\n",
    "        scores_by_qid[qid] = scores \n",
    "        scores = scipy.spatial.distance.squareform(scores)\n",
    "        link = linkage(scores, method=\"average\", metric=\"cosine\")\n",
    "        t = 1 \n",
    "        clust = fcluster(link, t=t, criterion='inconsistent')\n",
    "        clusts_by_qid[qid] = clust \n",
    "        answers_clustered = defaultdict(list)\n",
    "        ans_list = answers_by_qid[qid]\n",
    "        for i, idx in enumerate(clust):\n",
    "            answer = ans_list[i]\n",
    "            cluster_dict = {\"answer\": answer, \"id\": f\"g{i}\"} \n",
    "            answers_clustered[f\"g{idx}\"].append(cluster_dict)\n",
    "        answer_clusters[qid] = answers_clustered\n",
    "\n",
    "    return answer_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:21<00:00,  1.39it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers.utils import logging\n",
    "from BARTScore.abstract_class import BertSimilarityScore\n",
    "logging.set_verbosity(50)\n",
    "# logger = logging.get_logger(\"transformers\")\n",
    "# logger.info(\"INFO\")\n",
    "# logger.warning(\"WARN\")\n",
    "\n",
    "score_cls = BertSimilarityScore()\n",
    "pred_path = \"/brtx/602-nvme1/estengel/annotator_uncertainty/models/img2q_t5_small/output/predictions_forced.jsonl\"\n",
    "ans_clusts_by_qid = get_prediction_clusters(pred_path,\n",
    "                                        questions, \n",
    "                                        annotations,\n",
    "                                        score_cls=score_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a71203a0affc7207a6dfd2214cf786ae35ec96fb0be57392a936686760a696bf"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('cert')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
