{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "from pathlib import Path \n",
    "import os \n",
    "import subprocess\n",
    "data_path = \"/brtx/603-nvme2/estengel/annotator_uncertainty/vqa/dev_from_mturk_small/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "def min_gen(checkpoint, steps=200, lr=0.05, device=7, beta_text_loss=0.0):\n",
    "    path = os.environ.get(\"PATH\")\n",
    "    pythonpath = os.environ.get(\"PYTHONPATH\")\n",
    "    env_vars = {\"ALLENNLP_CACHE_ROOT\": \"/brtx/603-nvme2/estengel/annotator_uncertainty/vqa/\",\n",
    "                \"CHECKPOINT_DIR\": checkpoint,\n",
    "                \"TEST_DATA\": data_path,\n",
    "                \"CUDA_VISIBLE_DEVICES\": str(device),\n",
    "                \"PYTHONPATH\": f\"/home/estengel/annotator_uncertainty/models:{pythonpath}\",\n",
    "                \"PATH\": f\"/home/estengel/annotator_uncertainty/models/:{path}\"}\n",
    "    os.environ.update(env_vars)\n",
    "    p = subprocess.Popen([\"mkdir\", \"-p\", \"${CHECKPOINT_DIR}/output\"], stdout = subprocess.PIPE, stderr = subprocess.PIPE)\n",
    "    out, err = p.communicate()\n",
    "\n",
    "    command_str = f\"\"\"python -um allennlp min_gen \\\n",
    "    --include-package allennlp.data.dataset_readers \\\n",
    "    --include-package allennlp.training \\\n",
    "    {checkpoint}/ckpt/model.tar.gz \\\n",
    "    {data_path} \\\n",
    "    --cuda-device 0 \\\n",
    "    --predictions-output-file {checkpoint}/output/dev_min_gen_debug_steps_{steps}_lr_{lr}.jsonl \\\n",
    "    --descent-strategy steps \\\n",
    "    --num-descent-steps {steps} \\\n",
    "    --beta-text-loss {beta_text_loss} \\\n",
    "    --lr {lr}\n",
    "    \"\"\"\n",
    "\n",
    "    p = subprocess.Popen(command_str, shell=True, stdout = subprocess.PIPE, stderr = subprocess.PIPE)\n",
    "    out, err = p.communicate()\n",
    "    print(out.decode(\"utf8\")) \n",
    "\n",
    "    with open(f\"{checkpoint}/output/dev_min_gen_debug_steps_{steps}_lr_{lr}.jsonl\") as f1:\n",
    "        output_data = [json.loads(l) for l in f1]\n",
    "    return out, err, output_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vqa_loss: 12.537741661071777\n",
      "vqa_loss: 8.434691429138184\n",
      "vqa_loss: 6.6102705001831055\n",
      "vqa_loss: 5.011990547180176\n",
      "vqa_loss: 3.6233444213867188\n",
      "vqa_loss: 2.5490846633911133\n",
      "vqa_loss: 1.9018020629882812\n",
      "vqa_loss: 1.5915766954421997\n",
      "vqa_loss: 1.4349900484085083\n",
      "vqa_loss: 1.3381048440933228\n",
      "vqa_loss: 1.268572449684143\n",
      "vqa_loss: 1.2144206762313843\n",
      "vqa_loss: 1.1702513694763184\n",
      "vqa_loss: 1.133164405822754\n",
      "vqa_loss: 1.101380705833435\n",
      "vqa_loss: 1.0737273693084717\n",
      "vqa_loss: 1.0493673086166382\n",
      "vqa_loss: 1.027696967124939\n",
      "vqa_loss: 1.0082510709762573\n",
      "vqa_loss: 0.9906725287437439\n",
      "vqa_loss: 0.9746835827827454\n",
      "vqa_loss: 0.9600576162338257\n",
      "vqa_loss: 0.9466102123260498\n",
      "vqa_loss: 0.9341931343078613\n",
      "vqa_loss: 0.9226800203323364\n",
      "vqa_loss: 0.9119660258293152\n",
      "vqa_loss: 0.9019649028778076\n",
      "vqa_loss: 0.8926008939743042\n",
      "vqa_loss: 0.8838043212890625\n",
      "vqa_loss: 0.8755235075950623\n",
      "vqa_loss: 0.8677136898040771\n",
      "vqa_loss: 0.8603256940841675\n",
      "vqa_loss: 0.8533282279968262\n",
      "vqa_loss: 0.8466845750808716\n",
      "vqa_loss: 0.8403664827346802\n",
      "vqa_loss: 0.8343486785888672\n",
      "vqa_loss: 0.8286078572273254\n",
      "vqa_loss: 0.823123037815094\n",
      "vqa_loss: 0.8178778886795044\n",
      "vqa_loss: 0.8128547668457031\n",
      "vqa_loss: 0.8080360889434814\n",
      "vqa_loss: 0.8034072518348694\n",
      "vqa_loss: 0.7989612817764282\n",
      "vqa_loss: 0.7946847677230835\n",
      "vqa_loss: 0.7905651330947876\n",
      "vqa_loss: 0.7865931987762451\n",
      "vqa_loss: 0.7827611565589905\n",
      "vqa_loss: 0.7790600061416626\n",
      "vqa_loss: 0.775484561920166\n",
      "vqa_loss: 0.7720283269882202\n",
      "vqa_loss: 0.7686833739280701\n",
      "vqa_loss: 0.7654436230659485\n",
      "vqa_loss: 0.7623014450073242\n",
      "vqa_loss: 0.7592567205429077\n",
      "vqa_loss: 0.7562996745109558\n",
      "vqa_loss: 0.7534319758415222\n",
      "vqa_loss: 0.7506427764892578\n",
      "vqa_loss: 0.7479358911514282\n",
      "vqa_loss: 0.7452991008758545\n",
      "vqa_loss: 0.7427355051040649\n",
      "vqa_loss: 0.740239679813385\n",
      "vqa_loss: 0.7378085851669312\n",
      "vqa_loss: 0.7354406714439392\n",
      "vqa_loss: 0.7331310510635376\n",
      "vqa_loss: 0.7308787703514099\n",
      "vqa_loss: 0.7286820411682129\n",
      "vqa_loss: 0.7265369296073914\n",
      "vqa_loss: 0.7244433760643005\n",
      "vqa_loss: 0.722398042678833\n",
      "vqa_loss: 0.7203992605209351\n",
      "vqa_loss: 0.7184454202651978\n",
      "vqa_loss: 0.7165342569351196\n",
      "vqa_loss: 0.7146663665771484\n",
      "vqa_loss: 0.7128382325172424\n",
      "vqa_loss: 0.7110472917556763\n",
      "vqa_loss: 0.7092963457107544\n",
      "vqa_loss: 0.7075797319412231\n",
      "vqa_loss: 0.7059001922607422\n",
      "vqa_loss: 0.7042542099952698\n",
      "vqa_loss: 0.7026366591453552\n",
      "vqa_loss: 0.7010540962219238\n",
      "vqa_loss: 0.6995017528533936\n",
      "vqa_loss: 0.6979790925979614\n",
      "vqa_loss: 0.6964865326881409\n",
      "vqa_loss: 0.6950217485427856\n",
      "vqa_loss: 0.6935803890228271\n",
      "vqa_loss: 0.6921668648719788\n",
      "vqa_loss: 0.690779447555542\n",
      "vqa_loss: 0.6894163489341736\n",
      "vqa_loss: 0.6880756616592407\n",
      "vqa_loss: 0.686760663986206\n",
      "vqa_loss: 0.6854647994041443\n",
      "vqa_loss: 0.6841927766799927\n",
      "vqa_loss: 0.6829429864883423\n",
      "vqa_loss: 0.6817151308059692\n",
      "vqa_loss: 0.6805037260055542\n",
      "vqa_loss: 0.6793142557144165\n",
      "vqa_loss: 0.6781408786773682\n",
      "vqa_loss: 0.6769893169403076\n",
      "vqa_loss: 0.6758547425270081\n",
      "vqa_loss: 0.6747380495071411\n",
      "vqa_loss: 0.6736384630203247\n",
      "vqa_loss: 0.6725580096244812\n",
      "vqa_loss: 0.6714898943901062\n",
      "vqa_loss: 0.6704355478286743\n",
      "vqa_loss: 0.6694004535675049\n",
      "vqa_loss: 0.6683802604675293\n",
      "vqa_loss: 0.6673768758773804\n",
      "vqa_loss: 0.6663844585418701\n",
      "vqa_loss: 0.665406346321106\n",
      "vqa_loss: 0.6644442081451416\n",
      "vqa_loss: 0.6634957790374756\n",
      "vqa_loss: 0.6625567674636841\n",
      "vqa_loss: 0.6616346836090088\n",
      "vqa_loss: 0.6607210636138916\n",
      "vqa_loss: 0.6598213911056519\n",
      "vqa_loss: 0.658935546875\n",
      "vqa_loss: 0.6580598950386047\n",
      "vqa_loss: 0.6571959257125854\n",
      "vqa_loss: 0.6563405990600586\n",
      "vqa_loss: 0.6555018424987793\n",
      "vqa_loss: 0.6546694040298462\n",
      "vqa_loss: 0.6538485884666443\n",
      "vqa_loss: 0.6530371904373169\n",
      "vqa_loss: 0.6522364616394043\n",
      "vqa_loss: 0.6514467000961304\n",
      "vqa_loss: 0.6506667137145996\n",
      "vqa_loss: 0.6498954892158508\n",
      "vqa_loss: 0.6491327285766602\n",
      "vqa_loss: 0.6483789086341858\n",
      "vqa_loss: 0.6476345062255859\n",
      "vqa_loss: 0.6468994617462158\n",
      "vqa_loss: 0.6461713314056396\n",
      "vqa_loss: 0.6454546451568604\n",
      "vqa_loss: 0.6447435617446899\n",
      "vqa_loss: 0.6440406441688538\n",
      "vqa_loss: 0.6433457732200623\n",
      "vqa_loss: 0.6426596641540527\n",
      "vqa_loss: 0.6419815421104431\n",
      "vqa_loss: 0.6413102149963379\n",
      "vqa_loss: 0.6406453251838684\n",
      "vqa_loss: 0.6399891376495361\n",
      "vqa_loss: 0.6393395662307739\n",
      "vqa_loss: 0.6386964321136475\n",
      "vqa_loss: 0.6380605697631836\n",
      "vqa_loss: 0.6374303698539734\n",
      "vqa_loss: 0.6368086338043213\n",
      "vqa_loss: 0.636192262172699\n",
      "vqa_loss: 0.6355831623077393\n",
      "vqa_loss: 0.6349813938140869\n",
      "vqa_loss: 0.634384274482727\n",
      "vqa_loss: 0.6337926387786865\n",
      "vqa_loss: 0.6332076191902161\n",
      "vqa_loss: 0.6326280236244202\n",
      "vqa_loss: 0.6320522427558899\n",
      "vqa_loss: 0.631486713886261\n",
      "vqa_loss: 0.6309237480163574\n",
      "vqa_loss: 0.6303661465644836\n",
      "vqa_loss: 0.6298160552978516\n",
      "vqa_loss: 0.6292700171470642\n",
      "vqa_loss: 0.628730297088623\n",
      "vqa_loss: 0.628192663192749\n",
      "vqa_loss: 0.6276625990867615\n",
      "vqa_loss: 0.6271374225616455\n",
      "vqa_loss: 0.6266161203384399\n",
      "vqa_loss: 0.6260994672775269\n",
      "vqa_loss: 0.6255900859832764\n",
      "vqa_loss: 0.6250796318054199\n",
      "vqa_loss: 0.624580979347229\n",
      "vqa_loss: 0.6240807175636292\n",
      "vqa_loss: 0.623590350151062\n",
      "vqa_loss: 0.6231001615524292\n",
      "vqa_loss: 0.6226158142089844\n",
      "vqa_loss: 0.6221369504928589\n",
      "vqa_loss: 0.6216610670089722\n",
      "vqa_loss: 0.6211875677108765\n",
      "vqa_loss: 0.6207220554351807\n",
      "vqa_loss: 0.620259165763855\n",
      "vqa_loss: 0.619798481464386\n",
      "vqa_loss: 0.6193439960479736\n",
      "vqa_loss: 0.6188902258872986\n",
      "vqa_loss: 0.618443489074707\n",
      "vqa_loss: 0.6180002093315125\n",
      "vqa_loss: 0.6175585389137268\n",
      "vqa_loss: 0.6171221733093262\n",
      "vqa_loss: 0.6166892051696777\n",
      "vqa_loss: 0.6162605285644531\n",
      "vqa_loss: 0.6158329248428345\n",
      "vqa_loss: 0.6154109835624695\n",
      "vqa_loss: 0.6149920225143433\n",
      "vqa_loss: 0.6145773530006409\n",
      "vqa_loss: 0.6141660213470459\n",
      "vqa_loss: 0.6137535572052002\n",
      "vqa_loss: 0.6133497953414917\n",
      "vqa_loss: 0.6129477024078369\n",
      "vqa_loss: 0.6125460267066956\n",
      "vqa_loss: 0.6121506094932556\n",
      "vqa_loss: 0.6117570400238037\n",
      "vqa_loss: 0.6113667488098145\n",
      "vqa_loss: 0.610977828502655\n",
      "vqa_loss: 9.723631858825684\n",
      "vqa_loss: 0.3116016983985901\n",
      "vqa_loss: 0.3042733371257782\n",
      "vqa_loss: 0.2974490821361542\n",
      "vqa_loss: 0.2910814583301544\n",
      "vqa_loss: 0.28511589765548706\n",
      "vqa_loss: 0.2795182764530182\n",
      "vqa_loss: 0.2742503881454468\n",
      "vqa_loss: 0.26928088068962097\n",
      "vqa_loss: 0.2645840644836426\n",
      "vqa_loss: 0.26013562083244324\n",
      "vqa_loss: 0.25591856241226196\n",
      "vqa_loss: 0.2519091069698334\n",
      "vqa_loss: 0.2480926364660263\n",
      "vqa_loss: 0.24445755779743195\n",
      "vqa_loss: 0.24098628759384155\n",
      "vqa_loss: 0.2376701980829239\n",
      "vqa_loss: 0.2344958633184433\n",
      "vqa_loss: 0.23145350813865662\n",
      "vqa_loss: 0.22853532433509827\n",
      "vqa_loss: 0.22573497891426086\n",
      "vqa_loss: 0.22304557263851166\n",
      "vqa_loss: 0.2204532027244568\n",
      "vqa_loss: 0.21796077489852905\n",
      "vqa_loss: 0.2155575454235077\n",
      "vqa_loss: 0.21323785185813904\n",
      "vqa_loss: 0.21099890768527985\n",
      "vqa_loss: 0.2088364064693451\n",
      "vqa_loss: 0.20674647390842438\n",
      "vqa_loss: 0.20472264289855957\n",
      "vqa_loss: 0.20276616513729095\n",
      "vqa_loss: 0.20086798071861267\n",
      "vqa_loss: 0.1990266591310501\n",
      "vqa_loss: 0.1972433179616928\n",
      "vqa_loss: 0.19551287591457367\n",
      "vqa_loss: 0.1938295215368271\n",
      "vqa_loss: 0.19219981133937836\n",
      "vqa_loss: 0.19060967862606049\n",
      "vqa_loss: 0.18906626105308533\n",
      "vqa_loss: 0.187565416097641\n",
      "vqa_loss: 0.1861003041267395\n",
      "vqa_loss: 0.18467563390731812\n",
      "vqa_loss: 0.18328894674777985\n",
      "vqa_loss: 0.1819366216659546\n",
      "vqa_loss: 0.18061736226081848\n",
      "vqa_loss: 0.17933137714862823\n",
      "vqa_loss: 0.1780749261379242\n",
      "vqa_loss: 0.1768486201763153\n",
      "vqa_loss: 0.1756516546010971\n",
      "vqa_loss: 0.17448046803474426\n",
      "vqa_loss: 0.17333868145942688\n",
      "vqa_loss: 0.17222189903259277\n",
      "vqa_loss: 0.17112809419631958\n",
      "vqa_loss: 0.17005670070648193\n",
      "vqa_loss: 0.16901300847530365\n",
      "vqa_loss: 0.16798710823059082\n",
      "vqa_loss: 0.16698436439037323\n",
      "vqa_loss: 0.1660033017396927\n",
      "vqa_loss: 0.16504253447055817\n",
      "vqa_loss: 0.16410019993782043\n",
      "vqa_loss: 0.16317437589168549\n",
      "vqa_loss: 0.1622716188430786\n",
      "vqa_loss: 0.16138368844985962\n",
      "vqa_loss: 0.16051146388053894\n",
      "vqa_loss: 0.15965719521045685\n",
      "vqa_loss: 0.15881827473640442\n",
      "vqa_loss: 0.1579943746328354\n",
      "vqa_loss: 0.15718728303909302\n",
      "vqa_loss: 0.15639059245586395\n",
      "vqa_loss: 0.15561410784721375\n",
      "vqa_loss: 0.1548486351966858\n",
      "vqa_loss: 0.15409575402736664\n",
      "vqa_loss: 0.1533573716878891\n",
      "vqa_loss: 0.15262919664382935\n",
      "vqa_loss: 0.15191525220870972\n",
      "vqa_loss: 0.1512138843536377\n",
      "vqa_loss: 0.1505228877067566\n",
      "vqa_loss: 0.14984336495399475\n",
      "vqa_loss: 0.1491726189851761\n",
      "vqa_loss: 0.14851799607276917\n",
      "vqa_loss: 0.14787018299102783\n",
      "vqa_loss: 0.1472327709197998\n",
      "vqa_loss: 0.14660708606243134\n",
      "vqa_loss: 0.14598718285560608\n",
      "vqa_loss: 0.1453782618045807\n",
      "vqa_loss: 0.14477966725826263\n",
      "vqa_loss: 0.1441899538040161\n",
      "vqa_loss: 0.14360934495925903\n",
      "vqa_loss: 0.1430356204509735\n",
      "vqa_loss: 0.14247345924377441\n",
      "vqa_loss: 0.1419159471988678\n",
      "vqa_loss: 0.1413676142692566\n",
      "vqa_loss: 0.14082831144332886\n",
      "vqa_loss: 0.14029429852962494\n",
      "vqa_loss: 0.1397692859172821\n",
      "vqa_loss: 0.1392514556646347\n",
      "vqa_loss: 0.1387387365102768\n",
      "vqa_loss: 0.1382359117269516\n",
      "vqa_loss: 0.13773831725120544\n",
      "vqa_loss: 0.13724830746650696\n",
      "vqa_loss: 0.13676448166370392\n",
      "vqa_loss: 0.13628339767456055\n",
      "vqa_loss: 0.13581159710884094\n",
      "vqa_loss: 0.13534899055957794\n",
      "vqa_loss: 0.13488827645778656\n",
      "vqa_loss: 0.1344335824251175\n",
      "vqa_loss: 0.13398590683937073\n",
      "vqa_loss: 0.13354259729385376\n",
      "vqa_loss: 0.1331043392419815\n",
      "vqa_loss: 0.13267382979393005\n",
      "vqa_loss: 0.13224798440933228\n",
      "vqa_loss: 0.13182784616947174\n",
      "vqa_loss: 0.13141043484210968\n",
      "vqa_loss: 0.1309983879327774\n",
      "vqa_loss: 0.13059206306934357\n",
      "vqa_loss: 0.1301911324262619\n",
      "vqa_loss: 0.12979212403297424\n",
      "vqa_loss: 0.12940050661563873\n",
      "vqa_loss: 0.12901204824447632\n",
      "vqa_loss: 0.1286279559135437\n",
      "vqa_loss: 0.12825022637844086\n",
      "vqa_loss: 0.12787476181983948\n",
      "vqa_loss: 0.12750443816184998\n",
      "vqa_loss: 0.1271381825208664\n",
      "vqa_loss: 0.12677636742591858\n",
      "vqa_loss: 0.1264159381389618\n",
      "vqa_loss: 0.12605971097946167\n",
      "vqa_loss: 0.12571163475513458\n",
      "vqa_loss: 0.12536495923995972\n",
      "vqa_loss: 0.12502208352088928\n",
      "vqa_loss: 0.12468014657497406\n",
      "vqa_loss: 0.12434399873018265\n",
      "vqa_loss: 0.12401185184717178\n",
      "vqa_loss: 0.12368328124284744\n",
      "vqa_loss: 0.12335594743490219\n",
      "vqa_loss: 0.12303116917610168\n",
      "vqa_loss: 0.12271516025066376\n",
      "vqa_loss: 0.12239701300859451\n",
      "vqa_loss: 0.12208540737628937\n",
      "vqa_loss: 0.12177518010139465\n",
      "vqa_loss: 0.12146667391061783\n",
      "vqa_loss: 0.12116371840238571\n",
      "vqa_loss: 0.12086343765258789\n",
      "vqa_loss: 0.12056636065244675\n",
      "vqa_loss: 0.12027066946029663\n",
      "vqa_loss: 0.11997849494218826\n",
      "vqa_loss: 0.11968881636857986\n",
      "vqa_loss: 0.11940182000398636\n",
      "vqa_loss: 0.11911768466234207\n",
      "vqa_loss: 0.11883450299501419\n",
      "vqa_loss: 0.1185571625828743\n",
      "vqa_loss: 0.11828064918518066\n",
      "vqa_loss: 0.11800794303417206\n",
      "vqa_loss: 0.11773661524057388\n",
      "vqa_loss: 0.11746863275766373\n",
      "vqa_loss: 0.11720295250415802\n",
      "vqa_loss: 0.11693746596574783\n",
      "vqa_loss: 0.11667608469724655\n",
      "vqa_loss: 0.11641869693994522\n",
      "vqa_loss: 0.11616089195013046\n",
      "vqa_loss: 0.1159048080444336\n",
      "vqa_loss: 0.11565261334180832\n",
      "vqa_loss: 0.11540475487709045\n",
      "vqa_loss: 0.11515463143587112\n",
      "vqa_loss: 0.11490964144468307\n",
      "vqa_loss: 0.11466410756111145\n",
      "vqa_loss: 0.11442530900239944\n",
      "vqa_loss: 0.11418472230434418\n",
      "vqa_loss: 0.11394578963518143\n",
      "vqa_loss: 0.11371015757322311\n",
      "vqa_loss: 0.1134774386882782\n",
      "vqa_loss: 0.11324702948331833\n",
      "vqa_loss: 0.11301478743553162\n",
      "vqa_loss: 0.1127859428524971\n",
      "vqa_loss: 0.11256042867898941\n",
      "vqa_loss: 0.11233627796173096\n",
      "vqa_loss: 0.11211321502923965\n",
      "vqa_loss: 0.11189442127943039\n",
      "vqa_loss: 0.11167492717504501\n",
      "vqa_loss: 0.11145590990781784\n",
      "vqa_loss: 0.11124272644519806\n",
      "vqa_loss: 0.11102792620658875\n",
      "vqa_loss: 0.110817551612854\n",
      "vqa_loss: 0.11060436815023422\n",
      "vqa_loss: 0.11039666831493378\n",
      "vqa_loss: 0.11019022017717361\n",
      "vqa_loss: 0.10998322814702988\n",
      "vqa_loss: 0.10977970063686371\n",
      "vqa_loss: 0.10957808047533035\n",
      "vqa_loss: 0.1093759685754776\n",
      "vqa_loss: 0.10917464643716812\n",
      "vqa_loss: 0.10897855460643768\n",
      "vqa_loss: 0.10878270864486694\n",
      "vqa_loss: 0.10858626663684845\n",
      "vqa_loss: 0.10839394479990005\n",
      "vqa_loss: 0.10820012539625168\n",
      "vqa_loss: 0.10801047086715698\n",
      "vqa_loss: 0.10781969875097275\n",
      "vqa_loss: 0.10763183236122131\n",
      "vqa_loss: 0.10744568705558777\n",
      "vqa_loss: 23.488605499267578\n",
      "vqa_loss: 0.10927694290876389\n",
      "vqa_loss: 0.10917561501264572\n",
      "vqa_loss: 0.10907206684350967\n",
      "vqa_loss: 0.10897038131952286\n",
      "vqa_loss: 0.10886821895837784\n",
      "vqa_loss: 0.10876938700675964\n",
      "vqa_loss: 0.10866739600896835\n",
      "vqa_loss: 0.10856541246175766\n",
      "vqa_loss: 0.1084667518734932\n",
      "vqa_loss: 0.10836851596832275\n",
      "vqa_loss: 0.10826896876096725\n",
      "vqa_loss: 0.10817097127437592\n",
      "vqa_loss: 0.10807036608457565\n",
      "vqa_loss: 0.10797248035669327\n",
      "vqa_loss: 0.10787663608789444\n",
      "vqa_loss: 0.10777977854013443\n",
      "vqa_loss: 0.10767938941717148\n",
      "vqa_loss: 0.1075858548283577\n",
      "vqa_loss: 0.10748786479234695\n",
      "vqa_loss: 0.1073937937617302\n",
      "vqa_loss: 0.10729704797267914\n",
      "vqa_loss: 0.10720060765743256\n",
      "vqa_loss: 0.10710635781288147\n",
      "vqa_loss: 0.1070111021399498\n",
      "vqa_loss: 0.10691666603088379\n",
      "vqa_loss: 0.1068241074681282\n",
      "vqa_loss: 0.10673009604215622\n",
      "vqa_loss: 0.1066347137093544\n",
      "vqa_loss: 0.10654374957084656\n",
      "vqa_loss: 0.10645319521427155\n",
      "vqa_loss: 0.10635823756456375\n",
      "vqa_loss: 0.10626500099897385\n",
      "vqa_loss: 0.10617431998252869\n",
      "vqa_loss: 0.10608325153589249\n",
      "vqa_loss: 0.10599394142627716\n",
      "vqa_loss: 0.10590183734893799\n",
      "vqa_loss: 0.10581235587596893\n",
      "vqa_loss: 0.10572270303964615\n",
      "vqa_loss: 0.10563167184591293\n",
      "vqa_loss: 0.10554159432649612\n",
      "vqa_loss: 0.10545241832733154\n",
      "vqa_loss: 0.10536365211009979\n",
      "vqa_loss: 0.10527577996253967\n",
      "vqa_loss: 0.10518791526556015\n",
      "vqa_loss: 0.10510003566741943\n",
      "vqa_loss: 0.10501294583082199\n",
      "vqa_loss: 0.1049252450466156\n",
      "vqa_loss: 0.10483624041080475\n",
      "vqa_loss: 0.10475076735019684\n",
      "vqa_loss: 0.10466241091489792\n",
      "vqa_loss: 0.10457929968833923\n",
      "vqa_loss: 0.10449286550283432\n",
      "vqa_loss: 0.10440642386674881\n",
      "vqa_loss: 0.10432080924510956\n",
      "vqa_loss: 0.10423728823661804\n",
      "vqa_loss: 0.10415150970220566\n",
      "vqa_loss: 0.10406465083360672\n",
      "vqa_loss: 0.10398319363594055\n",
      "vqa_loss: 0.1038985475897789\n",
      "vqa_loss: 0.10381609946489334\n",
      "vqa_loss: 0.10373334586620331\n",
      "vqa_loss: 0.10364755988121033\n",
      "vqa_loss: 0.10356362909078598\n",
      "vqa_loss: 0.103480763733387\n",
      "vqa_loss: 0.1034027636051178\n",
      "vqa_loss: 0.103318952023983\n",
      "vqa_loss: 0.1032378077507019\n",
      "vqa_loss: 0.10315654426813126\n",
      "vqa_loss: 0.10307498276233673\n",
      "vqa_loss: 0.1029927134513855\n",
      "vqa_loss: 0.10291164368391037\n",
      "vqa_loss: 0.10283419489860535\n",
      "vqa_loss: 0.10275274515151978\n",
      "vqa_loss: 0.10267029702663422\n",
      "vqa_loss: 0.10259326547384262\n",
      "vqa_loss: 0.10251183062791824\n",
      "vqa_loss: 0.1024339571595192\n",
      "vqa_loss: 0.10235460847616196\n",
      "vqa_loss: 0.10227633267641068\n",
      "vqa_loss: 0.10219703614711761\n",
      "vqa_loss: 0.10211975872516632\n",
      "vqa_loss: 0.10204196721315384\n",
      "vqa_loss: 0.10196308046579361\n",
      "vqa_loss: 0.10188593715429306\n",
      "vqa_loss: 0.10180836915969849\n",
      "vqa_loss: 0.10173187404870987\n",
      "vqa_loss: 0.1016554906964302\n",
      "vqa_loss: 0.1015775054693222\n",
      "vqa_loss: 0.10150305181741714\n",
      "vqa_loss: 0.10142684727907181\n",
      "vqa_loss: 0.10134957730770111\n",
      "vqa_loss: 0.10127398371696472\n",
      "vqa_loss: 0.10119938850402832\n",
      "vqa_loss: 0.10112366825342178\n",
      "vqa_loss: 0.10105098783969879\n",
      "vqa_loss: 0.10097496956586838\n",
      "vqa_loss: 0.10090073943138123\n",
      "vqa_loss: 0.10082507133483887\n",
      "vqa_loss: 0.10075197368860245\n",
      "vqa_loss: 0.10067912191152573\n",
      "vqa_loss: 0.10060393065214157\n",
      "vqa_loss: 0.10053058713674545\n",
      "vqa_loss: 0.10045838356018066\n",
      "vqa_loss: 0.10038570314645767\n",
      "vqa_loss: 0.10031421482563019\n",
      "vqa_loss: 0.10024140775203705\n",
      "vqa_loss: 0.10016729682683945\n",
      "vqa_loss: 0.10009486228227615\n",
      "vqa_loss: 0.10002557188272476\n",
      "vqa_loss: 0.09995466470718384\n",
      "vqa_loss: 0.09988288581371307\n",
      "vqa_loss: 0.09980900585651398\n",
      "vqa_loss: 0.09973973035812378\n",
      "vqa_loss: 0.09967001527547836\n",
      "vqa_loss: 0.09959947317838669\n",
      "vqa_loss: 0.09952905774116516\n",
      "vqa_loss: 0.0994577407836914\n",
      "vqa_loss: 0.09938918054103851\n",
      "vqa_loss: 0.09931667149066925\n",
      "vqa_loss: 0.09925132244825363\n",
      "vqa_loss: 0.09917940944433212\n",
      "vqa_loss: 0.0991092324256897\n",
      "vqa_loss: 0.09904220700263977\n",
      "vqa_loss: 0.09897273778915405\n",
      "vqa_loss: 0.09890464693307877\n",
      "vqa_loss: 0.09883564710617065\n",
      "vqa_loss: 0.09876833856105804\n",
      "vqa_loss: 0.09870130568742752\n",
      "vqa_loss: 0.09863369166851044\n",
      "vqa_loss: 0.09856636822223663\n",
      "vqa_loss: 0.0984983965754509\n",
      "vqa_loss: 0.09843143075704575\n",
      "vqa_loss: 0.09836380183696747\n",
      "vqa_loss: 0.09829815477132797\n",
      "vqa_loss: 0.09823083877563477\n",
      "vqa_loss: 0.09816452860832214\n",
      "vqa_loss: 0.09809910506010056\n",
      "vqa_loss: 0.09803136438131332\n",
      "vqa_loss: 0.09796702861785889\n",
      "vqa_loss: 0.09790144115686417\n",
      "vqa_loss: 0.09783482551574707\n",
      "vqa_loss: 0.0977695882320404\n",
      "vqa_loss: 0.09770655632019043\n",
      "vqa_loss: 0.0976402536034584\n",
      "vqa_loss: 0.09757620841264725\n",
      "vqa_loss: 0.09751192480325699\n",
      "vqa_loss: 0.09744584560394287\n",
      "vqa_loss: 0.097384013235569\n",
      "vqa_loss: 0.09731853753328323\n",
      "vqa_loss: 0.0972534716129303\n",
      "vqa_loss: 0.0971907377243042\n",
      "vqa_loss: 0.09712836891412735\n",
      "vqa_loss: 0.09706360846757889\n",
      "vqa_loss: 0.09700289368629456\n",
      "vqa_loss: 0.09693855047225952\n",
      "vqa_loss: 0.09687533229589462\n",
      "vqa_loss: 0.09681212902069092\n",
      "vqa_loss: 0.09675083309412003\n",
      "vqa_loss: 0.09668844193220139\n",
      "vqa_loss: 0.09662725776433945\n",
      "vqa_loss: 0.09656446427106857\n",
      "vqa_loss: 0.0965028628706932\n",
      "vqa_loss: 0.09644084423780441\n",
      "vqa_loss: 0.09637971967458725\n",
      "vqa_loss: 0.09631858766078949\n",
      "vqa_loss: 0.09625770896673203\n",
      "vqa_loss: 0.09619633108377457\n",
      "vqa_loss: 0.0961349755525589\n",
      "vqa_loss: 0.09607652574777603\n",
      "vqa_loss: 0.09601480513811111\n",
      "vqa_loss: 0.09595391154289246\n",
      "vqa_loss: 0.09589463472366333\n",
      "vqa_loss: 0.09583523124456406\n",
      "vqa_loss: 0.09577339887619019\n",
      "vqa_loss: 0.09571404755115509\n",
      "vqa_loss: 0.09565597027540207\n",
      "vqa_loss: 0.09559675306081772\n",
      "vqa_loss: 0.09553710371255875\n",
      "vqa_loss: 0.09547776728868484\n",
      "vqa_loss: 0.09541831165552139\n",
      "vqa_loss: 0.0953599289059639\n",
      "vqa_loss: 0.09530165791511536\n",
      "vqa_loss: 0.09524267166852951\n",
      "vqa_loss: 0.09518560022115707\n",
      "vqa_loss: 0.09512607753276825\n",
      "vqa_loss: 0.09507014602422714\n",
      "vqa_loss: 0.09501270204782486\n",
      "vqa_loss: 0.09495437890291214\n",
      "vqa_loss: 0.09489473700523376\n",
      "vqa_loss: 0.09483999013900757\n",
      "vqa_loss: 0.09478159248828888\n",
      "vqa_loss: 0.09472262114286423\n",
      "vqa_loss: 0.0946665033698082\n",
      "vqa_loss: 0.09460989385843277\n",
      "vqa_loss: 0.09455383569002151\n",
      "vqa_loss: 0.09449812769889832\n",
      "vqa_loss: 0.09444332867860794\n",
      "vqa_loss: 0.09438630193471909\n",
      "vqa_loss: 0.0943286344408989\n",
      "vqa_loss: 16.421937942504883\n",
      "vqa_loss: 0.11236848682165146\n",
      "vqa_loss: 0.11220254004001617\n",
      "vqa_loss: 0.11203521490097046\n",
      "vqa_loss: 0.11187195777893066\n",
      "vqa_loss: 0.11170362681150436\n",
      "vqa_loss: 0.11154142022132874\n",
      "vqa_loss: 0.11138055473566055\n",
      "vqa_loss: 0.11121924221515656\n",
      "vqa_loss: 0.11105722934007645\n",
      "vqa_loss: 0.11089859902858734\n",
      "vqa_loss: 0.1107393354177475\n",
      "vqa_loss: 0.11058254539966583\n",
      "vqa_loss: 0.11042457818984985\n",
      "vqa_loss: 0.11026757210493088\n",
      "vqa_loss: 0.11011335998773575\n",
      "vqa_loss: 0.10995955020189285\n",
      "vqa_loss: 0.10980819910764694\n",
      "vqa_loss: 0.1096545159816742\n",
      "vqa_loss: 0.10950375348329544\n",
      "vqa_loss: 0.10935108363628387\n",
      "vqa_loss: 0.10920371860265732\n",
      "vqa_loss: 0.10905402898788452\n",
      "vqa_loss: 0.10890677571296692\n",
      "vqa_loss: 0.10875637084245682\n",
      "vqa_loss: 0.10861203819513321\n",
      "vqa_loss: 0.10846543312072754\n",
      "vqa_loss: 0.10832313448190689\n",
      "vqa_loss: 0.10817784816026688\n",
      "vqa_loss: 0.10803381353616714\n",
      "vqa_loss: 0.10789179801940918\n",
      "vqa_loss: 0.1077500432729721\n",
      "vqa_loss: 0.10760736465454102\n",
      "vqa_loss: 0.10746791958808899\n",
      "vqa_loss: 0.1073293536901474\n",
      "vqa_loss: 0.1071891337633133\n",
      "vqa_loss: 0.10705272853374481\n",
      "vqa_loss: 0.10691457986831665\n",
      "vqa_loss: 0.1067790761590004\n",
      "vqa_loss: 0.1066446304321289\n",
      "vqa_loss: 0.10650736838579178\n",
      "vqa_loss: 0.10637245327234268\n",
      "vqa_loss: 0.10623984038829803\n",
      "vqa_loss: 0.1061071902513504\n",
      "vqa_loss: 0.10597608238458633\n",
      "vqa_loss: 0.10584330558776855\n",
      "vqa_loss: 0.10571175813674927\n",
      "vqa_loss: 0.10558201372623444\n",
      "vqa_loss: 0.1054534763097763\n",
      "vqa_loss: 0.10532337427139282\n",
      "vqa_loss: 0.10519803315401077\n",
      "vqa_loss: 0.10506817698478699\n",
      "vqa_loss: 0.10493925958871841\n",
      "vqa_loss: 0.10481637716293335\n",
      "vqa_loss: 0.1046885997056961\n",
      "vqa_loss: 0.10456565022468567\n",
      "vqa_loss: 0.10444179177284241\n",
      "vqa_loss: 0.10431550443172455\n",
      "vqa_loss: 0.10419600456953049\n",
      "vqa_loss: 0.10407132655382156\n",
      "vqa_loss: 0.10395082086324692\n",
      "vqa_loss: 0.10382690280675888\n",
      "vqa_loss: 0.10370615869760513\n",
      "vqa_loss: 0.10358820855617523\n",
      "vqa_loss: 0.10346584767103195\n",
      "vqa_loss: 0.10334962606430054\n",
      "vqa_loss: 0.10323090106248856\n",
      "vqa_loss: 0.10311145335435867\n",
      "vqa_loss: 0.1029943898320198\n",
      "vqa_loss: 0.10287901014089584\n",
      "vqa_loss: 0.10276374220848083\n",
      "vqa_loss: 0.10264632105827332\n",
      "vqa_loss: 0.10253123193979263\n",
      "vqa_loss: 0.10241708904504776\n",
      "vqa_loss: 0.10230444371700287\n",
      "vqa_loss: 0.10218875110149384\n",
      "vqa_loss: 0.10207662731409073\n",
      "vqa_loss: 0.1019655391573906\n",
      "vqa_loss: 0.10185270756483078\n",
      "vqa_loss: 0.10174011439085007\n",
      "vqa_loss: 0.10163161903619766\n",
      "vqa_loss: 0.10152219235897064\n",
      "vqa_loss: 0.10141157358884811\n",
      "vqa_loss: 0.10130035132169724\n",
      "vqa_loss: 0.10119299590587616\n",
      "vqa_loss: 0.10108523070812225\n",
      "vqa_loss: 0.10097751766443253\n",
      "vqa_loss: 0.1008700504899025\n",
      "vqa_loss: 0.10076335817575455\n",
      "vqa_loss: 0.1006568968296051\n",
      "vqa_loss: 0.1005496010184288\n",
      "vqa_loss: 0.10044737905263901\n",
      "vqa_loss: 0.10034193843603134\n",
      "vqa_loss: 0.1002349928021431\n",
      "vqa_loss: 0.10013294965028763\n",
      "vqa_loss: 0.10002785921096802\n",
      "vqa_loss: 0.0999266505241394\n",
      "vqa_loss: 0.09982375800609589\n",
      "vqa_loss: 0.09972314536571503\n",
      "vqa_loss: 0.0996197834610939\n",
      "vqa_loss: 0.09951969981193542\n",
      "vqa_loss: 0.09941639751195908\n",
      "vqa_loss: 0.09931660443544388\n",
      "vqa_loss: 0.09921729564666748\n",
      "vqa_loss: 0.09911869466304779\n",
      "vqa_loss: 0.09901925921440125\n",
      "vqa_loss: 0.09892050176858902\n",
      "vqa_loss: 0.09882345050573349\n",
      "vqa_loss: 0.09872479736804962\n",
      "vqa_loss: 0.09862690418958664\n",
      "vqa_loss: 0.09853046387434006\n",
      "vqa_loss: 0.0984320342540741\n",
      "vqa_loss: 0.0983375683426857\n",
      "vqa_loss: 0.09824152290821075\n",
      "vqa_loss: 0.09814662486314774\n",
      "vqa_loss: 0.09805057942867279\n",
      "vqa_loss: 0.09795443713665009\n",
      "vqa_loss: 0.09786221385002136\n",
      "vqa_loss: 0.09776975959539413\n",
      "vqa_loss: 0.09767621010541916\n",
      "vqa_loss: 0.09758388251066208\n",
      "vqa_loss: 0.09749051183462143\n",
      "vqa_loss: 0.09739651530981064\n",
      "vqa_loss: 0.09730607271194458\n",
      "vqa_loss: 0.09721510857343674\n",
      "vqa_loss: 0.09712377935647964\n",
      "vqa_loss: 0.09703291952610016\n",
      "vqa_loss: 0.09694385528564453\n",
      "vqa_loss: 0.09685222059488297\n",
      "vqa_loss: 0.09676410257816315\n",
      "vqa_loss: 0.0966731458902359\n",
      "vqa_loss: 0.09658616036176682\n",
      "vqa_loss: 0.09649548679590225\n",
      "vqa_loss: 0.09640767425298691\n",
      "vqa_loss: 0.09632188826799393\n",
      "vqa_loss: 0.09623353183269501\n",
      "vqa_loss: 0.09614666551351547\n",
      "vqa_loss: 0.09606063365936279\n",
      "vqa_loss: 0.09597300738096237\n",
      "vqa_loss: 0.09588631987571716\n",
      "vqa_loss: 0.0957995131611824\n",
      "vqa_loss: 0.09571599215269089\n",
      "vqa_loss: 0.09563151746988297\n",
      "vqa_loss: 0.0955439954996109\n",
      "vqa_loss: 0.0954614207148552\n",
      "vqa_loss: 0.09537777304649353\n",
      "vqa_loss: 0.09529203921556473\n",
      "vqa_loss: 0.09520964324474335\n",
      "vqa_loss: 0.09512750059366226\n",
      "vqa_loss: 0.09504355490207672\n",
      "vqa_loss: 0.0949622318148613\n",
      "vqa_loss: 0.09488024562597275\n",
      "vqa_loss: 0.09479678422212601\n",
      "vqa_loss: 0.09471647441387177\n",
      "vqa_loss: 0.09463425725698471\n",
      "vqa_loss: 0.09455364942550659\n",
      "vqa_loss: 0.09447220712900162\n",
      "vqa_loss: 0.094392791390419\n",
      "vqa_loss: 0.09431396424770355\n",
      "vqa_loss: 0.09423228353261948\n",
      "vqa_loss: 0.0941537618637085\n",
      "vqa_loss: 0.09407458454370499\n",
      "vqa_loss: 0.09399546682834625\n",
      "vqa_loss: 0.09391599893569946\n",
      "vqa_loss: 0.0938389003276825\n",
      "vqa_loss: 0.09376049786806107\n",
      "vqa_loss: 0.09368059039115906\n",
      "vqa_loss: 0.09360630810260773\n",
      "vqa_loss: 0.09353010356426239\n",
      "vqa_loss: 0.09345170110464096\n",
      "vqa_loss: 0.09337694197893143\n",
      "vqa_loss: 0.09329817444086075\n",
      "vqa_loss: 0.09322298318147659\n",
      "vqa_loss: 0.093145951628685\n",
      "vqa_loss: 0.09307170659303665\n",
      "vqa_loss: 0.09299802035093307\n",
      "vqa_loss: 0.09292008727788925\n",
      "vqa_loss: 0.09284638613462448\n",
      "vqa_loss: 0.09277275949716568\n",
      "vqa_loss: 0.09269989281892776\n",
      "vqa_loss: 0.09262576699256897\n",
      "vqa_loss: 0.0925513505935669\n",
      "vqa_loss: 0.09247742593288422\n",
      "vqa_loss: 0.09240497648715973\n",
      "vqa_loss: 0.09233229607343674\n",
      "vqa_loss: 0.0922602042555809\n",
      "vqa_loss: 0.0921882912516594\n",
      "vqa_loss: 0.09211459010839462\n",
      "vqa_loss: 0.09204470366239548\n",
      "vqa_loss: 0.09197350591421127\n",
      "vqa_loss: 0.09190022945404053\n",
      "vqa_loss: 0.09183008968830109\n",
      "vqa_loss: 0.09175824373960495\n",
      "vqa_loss: 0.09168681502342224\n",
      "vqa_loss: 0.09161877632141113\n",
      "vqa_loss: 0.09154816716909409\n",
      "vqa_loss: 0.09147746115922928\n",
      "vqa_loss: 0.09140906482934952\n",
      "vqa_loss: 0.09134054183959961\n",
      "vqa_loss: 0.09126850962638855\n",
      "\n",
      "============================\n",
      "CHECKPOINT: /brtx/606-nvme1/estengel/annotator_uncertainty/models/vilt_bce_ce_weighted_0.5_1.0 LR: 0.05: STEPS: 200\n",
      "{'debug_tokens': ['What letters are attached to the pole?'], 'debug_images': ['/brtx/603-nvme2/estengel/annotator_uncertainty/vqa/balanced_real/COCO_train2014_000000276311.jpg'], 'debug_answer': [{'white': 1}], 'speaker_outputs': [['what is the what ?', 'what is the the picture ?', 'what is the what in the picture ?', 'what is the what in the photo ?', 'what is the color of the photo ?']], 'original_loss': 8.007278442382812, 'question_id': '276311000_4', 'final_loss': 0.610977828502655}\n",
      "{'debug_tokens': ['What railway does this train run along?'], 'debug_images': ['/brtx/603-nvme2/estengel/annotator_uncertainty/vqa/balanced_real/COCO_train2014_000000337875.jpg'], 'debug_answer': [{'grand canyon': 1}], 'speaker_outputs': [['what do these do you think this do they do ?', 'what do these do you think this do you do they do ?', 'what do these do these think this do you do you do they do ?', 'what do these do these think this do you do you do you do you do you think this ?', 'what do these do these think this do you do you do you do you do you think this do ?']], 'original_loss': 0.515713095664978, 'question_id': '337875005_3', 'final_loss': 0.10744568705558777}\n",
      "{'debug_tokens': ['What is on the computer screen?'], 'debug_images': ['/brtx/603-nvme2/estengel/annotator_uncertainty/vqa/balanced_real/COCO_train2014_000000420523.jpg'], 'debug_answer': [{'banana and strawberry': 1}], 'speaker_outputs': [['are the small trucks ?', 'are the trucks in the field ?', 'are the trucks in the pasture ?', 'are the trucks at the pitch ?', 'are the trucks parked in the field ?']], 'original_loss': 1.013826608657837, 'question_id': '420523002_5', 'final_loss': 0.0943286344408989}\n",
      "{'debug_tokens': ['What are the pizzas on?'], 'debug_images': ['/brtx/603-nvme2/estengel/annotator_uncertainty/vqa/balanced_real/COCO_train2014_000000172121.jpg'], 'debug_answer': [{'pepperoni and cheese': 1}], 'speaker_outputs': [[\"what color is the girl girl ' s table ?\", \"what is the girl girl ' s table ?\", \"what color is the girl ' s table ?\", 'what color is the girl girl holding the table ?', \"what color is the girl girl girl ' s table ?\"]], 'original_loss': 1.4217100143432617, 'question_id': '172121017_6', 'final_loss': 0.09126850962638855}\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "# checkpoints = [,\n",
    "#               \"/brtx/605-nvme1/estengel/annotator_uncertainty/models/vilt_bce_ce_double/\",\n",
    "#               \"/brtx/604-nvme1/estengel/annotator_uncertainty/models/vilt_bce_ce_2_layer_copy_sl/\"]\n",
    "checkpoints = [\"/brtx/606-nvme1/estengel/annotator_uncertainty/models/vilt_bce_ce_weighted_0.5_1.0\"]\n",
    "for checkpoint in checkpoints:\n",
    "    # for lr in [0.001, 0.01, 0.05, 0.1]:\n",
    "    #     for steps in [50, 100, 200, 400]:\n",
    "    for lr in [0.05]:\n",
    "        for steps in [200]:\n",
    "            out, err, output_data = min_gen(checkpoint=checkpoint,\n",
    "                                            steps=steps, lr=lr, device=7,\n",
    "                                            beta_text_loss=0.0000)\n",
    "            print(f\"============================\")\n",
    "            print(f\"CHECKPOINT: {checkpoint} LR: {lr}: STEPS: {steps}\")\n",
    "            for i in range(len(output_data)):\n",
    "                print(output_data[i])\n",
    "            print(f\"============================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = [\"/brtx/606-nvme1/estengel/annotator_uncertainty/models/vilt_bce_ce_weighted_1.0_0.5\"]\n",
    "for checkpoint in checkpoints:\n",
    "    for lr in [0.01, 0.05, 0.1]:\n",
    "        for steps in [200, 400]:\n",
    "            out, err, output_data = min_gen(checkpoint=checkpoint,\n",
    "                                            steps=steps, lr=lr, device=7)\n",
    "            print(f\"============================\")\n",
    "            print(f\"CHECKPOINT: {checkpoint} LR: {lr}: STEPS: {steps}\")\n",
    "            for i in range(len(output_data)):\n",
    "                print(output_data[i])\n",
    "            print(f\"============================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================\n",
      "CHECKPOINT: /brtx/602-nvme1/estengel/annotator_uncertainty/models/vilt_mlm/ LR: 0.01: STEPS: 2000\n",
      "{'debug_tokens': ['What letters are attached to the pole?'], 'debug_images': ['/brtx/603-nvme2/estengel/annotator_uncertainty/vqa/balanced_real/COCO_train2014_000000276311.jpg'], 'debug_answer': [{'white': 1}], 'speaker_outputs': [['what color are the letters ?', 'what letters are on the sign ?', 'what color are the signs ?', 'what letters are on the wall ?', 'what color are on the sign ?']], 'original_loss': 6.140600681304932, 'question_id': '276311000_4', 'final_loss': 0.13005851209163666}\n",
      "{'debug_tokens': ['What railway does this train run along?'], 'debug_images': ['/brtx/603-nvme2/estengel/annotator_uncertainty/vqa/balanced_real/COCO_train2014_000000337875.jpg'], 'debug_answer': [{'grand canyon': 1}], 'speaker_outputs': [['what railway does the train show ?', 'what railway does the train run on ?', 'what railway does this train run on ?', 'what railway station does this train show ?', 'what railway station does this train run ?']], 'original_loss': 0.08142612874507904, 'question_id': '337875005_3', 'final_loss': 0.014521575532853603}\n",
      "{'debug_tokens': ['What is on the computer screen?'], 'debug_images': ['/brtx/603-nvme2/estengel/annotator_uncertainty/vqa/balanced_real/COCO_train2014_000000420523.jpg'], 'debug_answer': [{'banana and strawberry': 1}], 'speaker_outputs': [['what is on the screen ?', 'what is on the computer screen ?', 'what is on the monitor ?', 'what is on the screen screen ?', 'what is on the monitor screen ?']], 'original_loss': 0.23518836498260498, 'question_id': '420523002_5', 'final_loss': 0.012846963480114937}\n",
      "{'debug_tokens': ['What are the pizzas on?'], 'debug_images': ['/brtx/603-nvme2/estengel/annotator_uncertainty/vqa/balanced_real/COCO_train2014_000000172121.jpg'], 'debug_answer': [{'pepperoni and cheese': 1}], 'speaker_outputs': [['what are the pizza ##s on ?', 'what are the pizza ##s eating ?', 'what are the pizza ##s sitting on ?', 'what are the pizza on ?', 'what are the computers on ?']], 'original_loss': 0.3659961223602295, 'question_id': '172121017_6', 'final_loss': 0.011005766689777374}\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "checkpoints = [\"/brtx/602-nvme1/estengel/annotator_uncertainty/models/vilt_mlm/\"]\n",
    "for checkpoint in checkpoints:\n",
    "    for lr in [0.01, 0.05, 0.1]:\n",
    "        for steps in [200, 400]:\n",
    "    # for lr in [0.01]:\n",
    "        # for steps in [2000]:\n",
    "            out, err, output_data = min_gen(checkpoint=checkpoint,\n",
    "                                            steps=steps, lr=lr, device=7)\n",
    "            print(f\"============================\")\n",
    "            print(f\"CHECKPOINT: {checkpoint} LR: {lr}: STEPS: {steps}\")\n",
    "            for i in range(len(output_data)):\n",
    "                print(output_data[i])\n",
    "            print(f\"============================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a71203a0affc7207a6dfd2214cf786ae35ec96fb0be57392a936686760a696bf"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('cert')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
