{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "import json \n",
    "import re \n",
    "import pathlib \n",
    "import numpy as np\n",
    "np.random.seed(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pred_file(path):\n",
    "    data_by_qid = {}\n",
    "    with open(path) as f1:\n",
    "        for line in f1:\n",
    "            batch = json.loads(line)\n",
    "            qids = batch['question_id']\n",
    "            preds = batch['speaker_utterances'][0]\n",
    "            for qid, pred in zip(qids, preds):\n",
    "                pred = re.sub(\"<[^>]*?>\", \"\", pred)\n",
    "                pred = pred.strip()\n",
    "                data_by_qid[qid] = pred\n",
    "    return data_by_qid\n",
    "\n",
    "\n",
    "def read_csv_data(path):\n",
    "    data_by_qid = {}\n",
    "    with open(path) as f1:\n",
    "        reader = csv.DictReader(f1)\n",
    "        for row in reader:\n",
    "            qid = row['Input.question_id']\n",
    "            for i, sent in enumerate(row['Answer.answer_questions']):\n",
    "                new_qid = f\"{qid}_{i}\"\n",
    "                data_by_qid[new_qid] = {\"sent\": sent, \"img_url\": row['Input.imgUrl']}\n",
    "    return data_by_qid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_questions = read_pred_file('/brtx/602-nvme1/estengel/annotator_uncertainty/models/img2q_t5_base_no_limit/output/test_set_predictions_forced.jsonl') \n",
    "ann_questions = json.load(open(\"/home/estengel/annotator_uncertainty/jimena_work/cleaned_data/csv/test_set/questions.json\"))['questions']\n",
    "ann_annotations = json.load(open(\"/home/estengel/annotator_uncertainty/jimena_work/cleaned_data/csv/test_set/annotations.json\"))['annotations']\n",
    "ann_img_ids = read_csv_data(\"/home/estengel/annotator_uncertainty/jimena_work/cleaned_data/csv/test_set/consolidate_data_repeat_all_data.csv\")\n",
    "original_questions = json.load(open(\"/brtx/603-nvme2/estengel/annotator_uncertainty/vqa/v2_OpenEnded_mscoco_train2014_questions.json\"))['questions']\n",
    "\n",
    "ann_questions = {q['question_id']: q for q in ann_questions}\n",
    "ann_annotations = {q['question_id']: q for q in ann_annotations}\n",
    "original_questions = {q['question_id']: q for q in original_questions}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_annotations['35884005_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "np.random.seed(12)\n",
    "# sample 100 question ids\n",
    "keys = [x for x in pred_questions.keys()]\n",
    "all_qids_short = [x.split(\"_\")[0] for x in keys]\n",
    "all_qids_long = keys\n",
    "all_idxs = [i for i in range(100)]\n",
    "chosen_idxs = np.random.choice(all_idxs, size=100, replace=False)\n",
    "chosen_qids_short = [all_qids_short[i] for i in chosen_idxs]\n",
    "chosen_qids_long = [all_qids_long[i] for i in chosen_idxs]\n",
    "\n",
    "# create lookup for anns by short qid and then postfix \n",
    "ann_by_short_qid = defaultdict(lambda: defaultdict(list))\n",
    "for qid, data in ann_questions.items():\n",
    "    annotation = ann_annotations[qid]\n",
    "    answer = annotation['answers'][0]['answer']\n",
    "    new_question = data['new_question']\n",
    "    qid, idx = qid.split(\"_\")\n",
    "    ann_by_short_qid[qid][new_question].append(answer) \n",
    "\n",
    "\n",
    "data = []\n",
    "# get the pred, annotator, original, and random questions for each qid \n",
    "for i, qid in enumerate(chosen_qids_long):\n",
    "    # get the pred question \n",
    "    pred = pred_questions[qid]\n",
    "    # get the annotator question \n",
    "    ann = ann_questions[qid]['new_question']\n",
    "    # get the original question\n",
    "    orig_qid = int(chosen_qids_short[i])\n",
    "    orig = original_questions[orig_qid]['question']\n",
    "    # get the image url\n",
    "    img_url = ann_img_ids[qid]['img_url']\n",
    "    # get the real answer \n",
    "    short_qid, idx = qid.split(\"_\")\n",
    "    idx = int(idx)\n",
    "    answer = ann_annotations[qid]['answers'][0]['answer']\n",
    "    # print(f\"predicted: {pred}\")\n",
    "    # print(f\"ann: {ann}\")\n",
    "    # print(f\"orig: {orig}\")\n",
    "    # print(f\"answer: {answer}\")\n",
    "    # get a distractor answer \n",
    "    # print(f\"idx: {idx}\")\n",
    "    distractor_questions = list(set(ann_by_short_qid[short_qid].keys()) - set([ann]))\n",
    "    # print(f\"distractor cands: {distractor_questions}\")\n",
    "    distractor_question = np.random.choice(distractor_questions, size=1)[0]\n",
    "    # print(f\"distractor: {distractor_question}\")\n",
    "    distractor_answer = np.random.choice(ann_by_short_qid[short_qid][distractor_question], size=1)[0]\n",
    "    # print(f\"distractor: {distractor_answer}\")\n",
    "\n",
    "\n",
    "    questions_and_types = [(pred, \"pred\"), (ann, \"ann\"), (orig, \"orig\")]\n",
    "    for quest, qtype in questions_and_types:\n",
    "        main_datapoint = {\"qid\": qid, \"question\": quest, \"question_type\": qtype, \"answer\": answer, \"img_url\": json.loads(img_url), \"is_distractor\": False}\n",
    "        dist_datapoint = {\"qid\": qid, \"question\": quest, \"question_type\": qtype, \"answer\": distractor_answer, \"img_url\": json.loads(img_url), \"is_distractor\": True}\n",
    "        data.append(main_datapoint)\n",
    "        data.append(dist_datapoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "\n",
    "# randomize data for HIT\n",
    "np.random.seed(12)\n",
    "\n",
    "metadata_keys = [\"qid\", \"question_type\", \"is_distractor\"]\n",
    "data_for_hit = []\n",
    "for datapoint in data: \n",
    "    datapoint = {k: json.dumps(v) if k in metadata_keys else v for k, v in datapoint.items() }\n",
    "    data_for_hit.append(datapoint)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'qid': '\"44463014_5\"', 'question': 'Where is the car?', 'question_type': '\"pred\"', 'answer': 'near road', 'img_url': 'https://cs.jhu.edu/~esteng/images_for_hit/COCO_train2014_000000044463.jpg', 'is_distractor': 'false'}\n",
      "{'qid': '\"44463014_5\"', 'question': 'Where is the car?', 'question_type': '\"pred\"', 'answer': 'on poles', 'img_url': 'https://cs.jhu.edu/~esteng/images_for_hit/COCO_train2014_000000044463.jpg', 'is_distractor': 'true'}\n",
      "{'qid': '\"44463014_5\"', 'question': 'What is the sign board by?', 'question_type': '\"ann\"', 'answer': 'near road', 'img_url': 'https://cs.jhu.edu/~esteng/images_for_hit/COCO_train2014_000000044463.jpg', 'is_distractor': 'false'}\n",
      "{'qid': '\"44463014_5\"', 'question': 'What is the sign board by?', 'question_type': '\"ann\"', 'answer': 'on poles', 'img_url': 'https://cs.jhu.edu/~esteng/images_for_hit/COCO_train2014_000000044463.jpg', 'is_distractor': 'true'}\n",
      "{'qid': '\"44463014_5\"', 'question': 'Where is the sign board placed?', 'question_type': '\"orig\"', 'answer': 'near road', 'img_url': 'https://cs.jhu.edu/~esteng/images_for_hit/COCO_train2014_000000044463.jpg', 'is_distractor': 'false'}\n",
      "{'qid': '\"44463014_5\"', 'question': 'Where is the sign board placed?', 'question_type': '\"orig\"', 'answer': 'on poles', 'img_url': 'https://cs.jhu.edu/~esteng/images_for_hit/COCO_train2014_000000044463.jpg', 'is_distractor': 'true'}\n"
     ]
    }
   ],
   "source": [
    "# print(\"\\n\".join([str(x) for x in data_for_hit[0:6]]))\n",
    "# print(data_for_hit[])\n",
    "# print(data[4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_keys = ['indices_and_questions']\n",
    "# shuffle data for actual HIT \n",
    "np.random.shuffle(data_for_hit)\n",
    "with open(\"../eval_hit/csvs/data_for_ordinal_hit.csv\", \"w\") as f1:\n",
    "    writer = csv.DictWriter(f1, fieldnames=data_for_hit[0].keys())\n",
    "    writer.writeheader()\n",
    "    for row in data_for_hit:\n",
    "        # row = {k: json.dumps(v) if v in json_keys else v for k, v in row.items() }\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('cert')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a71203a0affc7207a6dfd2214cf786ae35ec96fb0be57392a936686760a696bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
